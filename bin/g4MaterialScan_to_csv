#!/usr/bin/env python3

# SPDX-License-Identifier: LGPL-3.0-or-later
# Copyright (C) 2023 Chao Peng
'''
    A script to run a 2D (eta, phi) scan using Geant4 kernel.
    Scan results are collected in a CSV format file.
'''

import os
import errno
import argparse
import pandas as pd
import numpy as np
from io import StringIO
from collections import OrderedDict as odict

import DDG4
import dd4hep
import g4units

# pd.set_option('display.max_rows', 1000)
PROGRESS_STEP = 10


class g4MaterialScanner:
    # singleton to prevent kernel from being accessed by multiple sources
    _self = None

    def __new__(cls):
        if cls._self is None:
            cls._self = super().__new__(cls)
        return cls._self

    def __init__(self, compact, phy_list='QGSP_BERT'):
        kernel = DDG4.Kernel()
        kernel.loadGeometry(compact)
        DDG4.Core.setPrintFormat(str("%-32s %6s %s"))
        geant4 = DDG4.Geant4(kernel)
        geant4.setupCshUI(ui=None)
        for i in geant4.description.detectors():
            o = DDG4.DetElement(i.second.ptr())
            sd = geant4.description.sensitiveDetector(o.name())
            if sd.isValid():
                typ = sd.type()
            if typ in geant4.sensitive_types:
                geant4.setupDetector(o.name(), geant4.sensitive_types[typ])
            else:
                logger.error('+++  %-32s type:%-12s  --> Unknown Sensitive type: %s', o.name(), typ, typ)
                sys.exit(errno.EINVAL)

        scan = DDG4.SteppingAction(kernel, 'Geant4MaterialScanner/MaterialScan')
        kernel.steppingAction().adopt(scan)

        # Now build the physics list:
        geant4.setupPhysics(phy_list)
        kernel.configure()
        kernel.initialize()

        self.kernel = kernel
        self.geant4 = geant4

    def __del__(self):
        self.kernel.terminate()

    def scan(position, direction):
        self.geant4.setupGun('Scanner',
                             Standalone=True,
                             particle='geantino',
                             energy=20 8 g4units.GeV,
                             position='({},{},{})'.format(*position),
                             direction='({},{},{})'.format(*direction),
                             multiplicity=1,
                             isotrop=False)

        self.kernel.NumEvents = 1
        self.kernel.run()

'''
    A parser function to convert output from g4MaterialScan to a pandas dataframe
    compact: is path to compact file
    start_point: a list or tuple for 3D coordinates (e.g., 0,0,0)
    direction: a list or tuple for direction (e.g., 0.1,0.2,1.0)
    return: a dataframe for materialScan results
'''
def g4_material_scan(compact, start_point, direction, timeout=200):
    EXEC_NAME = 'g4MaterialScan'
    cmd = '{} --compact={} --position=\"{},{},{}\" --direction=\"{},{},{}\"'\
          .format(EXEC_NAME, compact, *np.hstack([start_point, direction]))
    print(cmd)
    output = os.popen(cmd).read()
    # output = subprocess.check_output(cmd.split(' '), timeout=timeout).decode('UTF-8')

    # find material scan lines
    lines = []
    add_line = False

    for l in output.split('\n'):
        if add_line:
            lines.append(l.strip())
        if l.strip().startswith('MaterialScan'):
            add_line = True


    # NOTE: the code below is for materialScan output as of 03/05/2023
    # it may need change if the output format is changed
    scans = []
    first_digit = False
    for i, l in enumerate(lines):
        line = l.strip('| ')
        if not first_digit and not line[:1].isdigit():
            continue
        first_digit = True
        if not line[:1].isdigit():
            break
        # break coordinates for endpoint, which has a format of (x, y, z)
        scans.append(line.strip('| ').translate({ord(i): None for i in '()'}).replace(',', ' '))

    cols = [
        'material', 'Z', 'A', 'density',
        'rad_length', 'int_length', 'thickness', 'path_length',
        'int_X0', 'int_lambda', 'end_x', 'end_y', 'end_z'
        ]

    dft = pd.read_csv(StringIO('\n'.join(scans)), sep='\s+', header=None, index_col=0, names=cols)
    return dft.astype({key: np.float64 for key in cols[1:]})


'''
    A helper function to convert a string (<min>[:<max>[:<step>]]) to an array
'''
def args_array(arg, step=1, include_end=True):
    vals = [float(x.strip()) for x in arg.split(':')]
    # empty or only one value
    if len(vals) < 2:
        return np.array(vals)
    # has step input
    if len(vals) > 2:
        step = vals[2]
    # inclusion of the endpoint (max)
    if include_end:
        vals[1] += step
    return np.arange(vals[0], vals[1], step)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
            prog='g4MaterialScan_to_csv',
            description = 'A python script to run \"g4MaterialScan\" and save the results in CSV format.'
                        + '\n       ' # 7 spaces for "usage: "
                        + 'The scan is conducted with given ranges for both eta and phi.'
            )
    parser.add_argument(
            '-c', '--compact', dest='compact', required=True,
            help='Top-level xml file of the detector description.'
            )
    parser.add_argument(
            '-o', '--output', default='g4mat_scan.csv',
            help='Path of the output csv file. Support python formatting of args, e.g., g4mat_scan_{eta}_{phi}.csv.'
            )
    parser.add_argument(
            '--start-point', default='0,0,0',
            help='Start point of the scan, use the format \"x,y,z\", unit is cm.'
            )
    parser.add_argument(
            '--eta', default='-4.0:4.0:0.1',
            help='Eta range, in the format of \"<min>[:<max>[:<step>]]\".'
            )
    parser.add_argument(
            '--phi', default='0:30:1',
            help='Phi angle range, in the format of \"<min>[:<max>[:<step>]]\" (degree).'
            )
    parser.add_argument(
            '--mat-buffer-size', type=int, default=50,
            help='Material buffer size.'
            )
    args = parser.parse_args()

    if not os.path.exists(args.compact):
        print('Cannot find compact file {}'.format(args.compact))
        exit(-1)

    start_point = np.array([float(v.strip()) for v in args.start_point.split(',')])
    etas = args_array(args.eta)
    phis = args_array(args.phi)
    # sanity check
    if not len(phis):
        print('No phi values from the input {}, aborted!'.format(args.phi))
        exit(-1)
    mats_indices = odict()

    # build a multi-indices for the data frame
    eta_phi = []
    # should exist in the scan as int_{value_type}
    value_types = ['X0', 'lambda']
    # a data buffer for the X0 values of ((eta, phi), materials, (X0, Lambda))
    data = np.zeros(shape=(len(etas)*len(phis), args.mat_buffer_size, len(value_types)))
    # scan eta, phi
    for i, eta in enumerate(etas):
        if i % PROGRESS_STEP == 0:
            print('Scanned {:d}/{:d} lines for eta in [{:.2f}, {:.2f}], each with {:d} phi values in [{:.2f}, {:.2f}] (degree).'\
                  .format(i, len(etas), etas[0], etas[-1], len(phis), phis[0], phis[-1])
                  )
        for j, phi in enumerate(phis):
            # scan
            direction = (np.cos(phi/180.*np.pi), np.sin(phi/180.*np.pi), np.sinh(eta))
            dfa = g4_material_scan(args.compact, start_point, direction)
            for vt in value_types:
                dfa.loc[:, vt] = dfa['int_{}'.format(vt)].diff(1).fillna(dfa['int_{}'.format(vt)])

            # scan result
            single_scan = dfa.groupby('material')[value_types].sum()
            # print(single_scan)
            for mat, xvals in single_scan.iterrows():
                if mat not in mats_indices:
                    if len(mats_indices) >= args.mat_buffer_size:
                        print('Number of materials exceeds MAT_BUFFER_SIZE ({:d}), dropped material {}.'.format(args.mat_buffer_size, mat))
                        print('Hint: increase the buffer size with --mat-buffer-size.')
                        continue
                    mats_indices[mat] = len(mats_indices)
                k = mats_indices.get(mat)
                data[len(eta_phi), k] = xvals.values
            eta_phi.append((eta, phi))

    # save results
    result = dict()
    for i, vt in enumerate(value_types):
        indices = pd.MultiIndex.from_tuples(eta_phi, names=['eta', 'phi'])
        result[vt] = pd.DataFrame(columns=mats_indices.keys(), index=indices, data=data[:, :len(mats_indices), i])
    out_path = args.output.format(**vars(args))
    pd.concat(result, names=['value_type']).to_csv(out_path, sep="\t")
    print('Scanned results saved to \"{}\"'.format(out_path))
